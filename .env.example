# ===== Provider/API keys =====
GEMINI_API_KEY=

# ===== Tracing (Langfuse) =====
LANGFUSE_ENABLED=true
LANGFUSE_PUBLIC_KEY=
LANGFUSE_SECRET_KEY=
LANGFUSE_HOST=https://cloud.langfuse.com

# ===== Cache / Redis =====
CACHE_ENABLED=true
REDIS_URL=redis://redis:6379/0

# ===== Retrieval / Vector store =====
VECTOR_STORE=FAISS
FAISS_INDEX_PATH=data/faiss.index
DOC_MAP_PATH=data/doc_map.json
FAISS_METRIC=ip
FAISS_NORMALIZE=true

# ===== App behavior =====
OFFLINE_MODE=false
CONFIDENCE_THRESHOLD=0.40
ANSWER_CACHE_TTL_SECONDS=604800
SUMMARY_CACHE_TTL_SECONDS=604800
SEMANTIC_CACHE_THRESHOLD=0.92
RATE_LIMIT_PER_MINUTE=5

# ===== Reranker / thresholds =====
RERANKER_BACKEND=cross-encoder
RERANKER_MODEL=cross-encoder/ms-marco-MiniLM-L-6-v2
RERANK_THRESHOLD=0.015
QUERY_REFINE_ENABLED=true
SUMMARIZER_MAX_CHUNKS=20

# ===== Embeddings / Models =====
# Unify on Gemini embeddings
EMBEDDING_MODEL=gemini-embedding-001
GEMINI_MODEL=gemini-2.5-pro
GEMINI_FAST_MODEL=gemini-2.5-flash
GEMINI_REASONING_MODEL=gemini-2.5-pro

# ===== Evaluation / Judge =====
# Enable Gemini LLM-as-judge enrichment in evaluation service (true by default)
EVAL_LLM_ENABLED=True